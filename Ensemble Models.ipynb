{"cells":[{"cell_type":"markdown","metadata":{"id":"hbRDIfn-rq6_"},"source":["# ENSEMBLE MODEL TABLE OF CONTENT\n","- **Uploader**\n","- **Data Prep**\n","- **Categorical Data Prep and Modeling**\n","  - ADHD Model - Undersampled GBDT\n","  - Sex_F Model - Oversampled GBDT\n","- **Quantitative Data Prep and Modeling**\n","- **FCM Data Prep and Modeling**\n","- **Emsemble Modeling - Stacking Method**\n","- **Kaggle Submission Maker**\n","\n","*Maya: I am up to getting best models for Cat rn, if anyone wants to find and input the best models along with their dataprep (dataset modifications) that would be great!*\n","\n","*Kayla: I updated the categorical data prep and modeling bc we had an updated file with the fixed code after Preston pointed out our sampling mix up. I have also added the best models for quantitative data (even though I get different results than your separate colab for optuna ?)*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":0},"id":"JRkLQEJhdqV5"},"outputs":[{"name":"stdout","output_type":"stream","text":["newwidsdatathon2025.zip\n","Archive:  newwidsdatathon2025.zip\n","replace Data Dictionary.xlsx? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["#@title uploader\n","file_id = \"1rVYGtWzw9s9Bw80-XaIN8gYBsBG79K8B\" #@param {type:\"string\"}\n","!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# PyDrive reference:\n","# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n","\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","from googleapiclient.discovery import build\n","drive_service = build('drive', 'v3')\n","\n","# Replace the assignment below with your file ID\n","# to download a different file.\n","#\n","# A file ID looks like: 1gLBqEWEBQDYbKCDigHnUXNTkzl-OslSO\n","\n","import io\n","from googleapiclient.http import MediaIoBaseDownload\n","\n","request = drive_service.files().get_media(fileId=file_id)\n","downloaded = io.BytesIO()\n","downloader = MediaIoBaseDownload(downloaded, request)\n","done = False\n","while done is False:\n","  # _ is a placeholder for a progress object that we ignore.\n","  # (Our file is small, so we skip reporting progress.)\n","  _, done = downloader.next_chunk()\n","\n","fileId = drive.CreateFile({'id': file_id }) #DRIVE_FILE_ID is file id example: 1iytA1n2z4go3uVCwE_vIKouTKyIDjEq\n","print(fileId['title'])\n","fileId.GetContentFile(fileId['title'])  # Save Drive file as a local file\n","\n","!unzip {fileId['title']}"]},{"cell_type":"markdown","metadata":{"id":"5h3kt68fheMu"},"source":["## Data Prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPaTXUNOdy8R"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","#!pip install scikit-learn\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from imblearn.under_sampling import RandomUnderSampler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQ2prZtad4sN"},"outputs":[],"source":["#all datasets\n","train_quantitative = pd.read_excel('TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx')\n","train_answers = pd.read_excel('TRAIN_NEW/TRAINING_SOLUTIONS.xlsx')\n","train_categorical = pd.read_excel(\"TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n","train_solutions = pd.read_excel('TRAIN_NEW/TRAINING_SOLUTIONS.xlsx')\n","fcm = pd.read_csv(\"TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n","fcm_solutions = pd.read_excel(\"TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")\n","graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KREzsGYO5DKt"},"outputs":[],"source":["#loading in datasets (I have it stored a different way)\n","train_categorical = pd.read_excel(\"/content/TRAIN_CATEGORICAL_METADATA.xlsx\")\n","train_solutions = pd.read_excel(\"/content/TRAINING_SOLUTIONS.xlsx\")\n","train_quantitative = pd.read_excel(\"/content/TRAIN_QUANTITATIVE_METADATA.xlsx\")"]},{"cell_type":"markdown","metadata":{"id":"lpoJBLMmhhOq"},"source":["## Categorical Data Prep + Modeling\n","### ADHD - Oversampling gradient boosted trees (gave worse accuracy?)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":20,"status":"ok","timestamp":1742663595577,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"C9dAlriQezux","outputId":"42136ae5-4e74-486d-c164-7513c6c6c512"},"outputs":[{"name":"stdout","output_type":"stream","text":["Basic_Demos_Enroll_Year\n","2018    415\n","2019    312\n","2017    254\n","2016    191\n","2015     36\n","2020      5\n","Name: count, dtype: int64\n","\n","\n","Basic_Demos_Study_Site\n","1    652\n","3    430\n","4    120\n","2     11\n","Name: count, dtype: int64\n","\n","\n","PreInt_Demos_Fam_Child_Ethnicity\n","0.0    777\n","1.0    296\n","2.0     77\n","3.0     20\n","Name: count, dtype: int64\n","\n","\n","PreInt_Demos_Fam_Child_Race\n","0.0     573\n","8.0     195\n","1.0     181\n","2.0     128\n","3.0      30\n","9.0      23\n","10.0     11\n","4.0      10\n","11.0      6\n","7.0       2\n","Name: count, dtype: int64\n","\n","\n","MRI_Track_Scan_Location\n","2.0    532\n","3.0    463\n","1.0    179\n","4.0     36\n","Name: count, dtype: int64\n","\n","\n","Barratt_Barratt_P1_Edu\n","21.0    470\n","18.0    421\n","15.0    162\n","12.0     97\n","9.0      28\n","6.0      15\n","3.0       5\n","Name: count, dtype: int64\n","\n","\n","Barratt_Barratt_P1_Occ\n","0.0     286\n","35.0    219\n","45.0    187\n","30.0    154\n","40.0    154\n","25.0     79\n","15.0     35\n","5.0      31\n","20.0     31\n","10.0      6\n","Name: count, dtype: int64\n","\n","\n","Barratt_Barratt_P2_Edu\n","21.0    323\n","18.0    301\n","15.0    166\n","12.0    162\n","9.0      44\n","6.0      14\n","3.0       5\n","Name: count, dtype: int64\n","\n","\n","Barratt_Barratt_P2_Occ\n","45.0    239\n","35.0    195\n","30.0    149\n","40.0    116\n","15.0     86\n","0.0      65\n","20.0     41\n","5.0      38\n","10.0     37\n","25.0     25\n","Name: count, dtype: int64\n","\n","\n"]}],"source":["#drop id\n","for feature in train_categorical.drop(columns = ['participant_id']).columns:\n","  print(train_categorical[feature].value_counts())\n","  print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F5MEr1HKnfnr"},"outputs":[],"source":["df = pd.merge(train_categorical, train_solutions, on='participant_id')\n","\n","participant_ids = df['participant_id']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1742664226629,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"Om_LGFOS2HdN","outputId":"816b5476-ed76-437f-9ee9-fbebfa5e5289"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eparticipant_id\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBasic_Demos_Enroll_Year\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBasic_Demos_Study_Site\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ePreInt_Demos_Fam_Child_Ethnicity\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ePreInt_Demos_Fam_Child_Race\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eMRI_Track_Scan_Location\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBarratt_Barratt_P1_Edu\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBarratt_Barratt_P1_Occ\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBarratt_Barratt_P2_Edu\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBarratt_Barratt_P2_Occ\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eADHD_Outcome\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eSex_F\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\u003cbr\u003e\u003clabel\u003e\u003cb\u003edtype:\u003c/b\u003e int64\u003c/label\u003e"],"text/plain":["participant_id                      0\n","Basic_Demos_Enroll_Year             0\n","Basic_Demos_Study_Site              0\n","PreInt_Demos_Fam_Child_Ethnicity    0\n","PreInt_Demos_Fam_Child_Race         0\n","MRI_Track_Scan_Location             0\n","Barratt_Barratt_P1_Edu              0\n","Barratt_Barratt_P1_Occ              0\n","Barratt_Barratt_P2_Edu              0\n","Barratt_Barratt_P2_Occ              0\n","ADHD_Outcome                        0\n","Sex_F                               0\n","dtype: int64"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G84Qf-GOnvVX"},"outputs":[],"source":["#fill missing NA values\n","df.fillna({'PreInt_Demos_Fam_Child_Ethnicity':df['PreInt_Demos_Fam_Child_Ethnicity'].mean()}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aP7wPs_V2b1q"},"outputs":[],"source":["df.fillna({'PreInt_Demos_Fam_Child_Race':df['PreInt_Demos_Fam_Child_Race'].mean()}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auPaFL2V3J0p"},"outputs":[],"source":["df.fillna({'MRI_Track_Scan_Location':df['MRI_Track_Scan_Location'].mean()}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xTv5Rgy3Q02"},"outputs":[],"source":["df.fillna({'Barratt_Barratt_P1_Edu':df['Barratt_Barratt_P1_Edu'].mean()}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hce0846k3XmR"},"outputs":[],"source":["df.fillna({'Barratt_Barratt_P1_Occ':df['Barratt_Barratt_P1_Occ'].mean()}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SD_ulVLB3ebt"},"outputs":[],"source":["df.fillna({'Barratt_Barratt_P2_Edu':df['Barratt_Barratt_P2_Edu'].mean()}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfuiNvfW3kUk"},"outputs":[],"source":["df.fillna({'Barratt_Barratt_P2_Occ':df['Barratt_Barratt_P2_Occ'].mean()}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3GP5cyM5JVV"},"outputs":[],"source":["X = df.drop(columns=['Sex_F', 'participant_id'])\n","y = df['Sex_F']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=42)\n","X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"znQZ1QJNs-Nr"},"source":["Running grid search got:\n","\n","{'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} Validation accuracy: 0.7366255144032922"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"elapsed":51,"status":"error","timestamp":1742664326082,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"02gNAJYro1v-","outputId":"9902259b-ea76-4985-fd6d-829178ebea9b"},"outputs":[{"ename":"KeyError","evalue":"\"['ADHD_Outcome'] not found in axis\"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-70-671c1d0acb7c\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_ADHD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ADHD_Outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_train_ADHD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ADHD_Outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 7\u001b[0;31m \u001b[0mx_test_ADHD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ADHD_Outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_test_ADHD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ADHD_Outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-\u003e 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['ADHD_Outcome'] not found in axis\""]}],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","\n","X_train_ADHD = X_train_resampled.drop(columns=['ADHD_Outcome'])\n","y_train_ADHD = X_train_resampled['ADHD_Outcome']\n","x_test_ADHD = X_test.drop(columns=['ADHD_Outcome'])\n","y_test_ADHD = X_test['ADHD_Outcome']\n","\n","# Initialize GBDT model with best parameters\n","gbdt_cat_ADHD = GradientBoostingClassifier(\n","    learning_rate=0.01,\n","    max_depth=3,\n","    min_samples_leaf=2,\n","    min_samples_split=2,\n","    n_estimators=200,\n","    random_state=42\n",")\n","\n","# Train the model\n","gbdt_cat_ADHD.fit(X_train_ADHD, y_train_ADHD)\n","\n","# Evaluate on validation set\n","y_pred = gbdt_cat_ADHD.predict(x_test_ADHD)\n","\n","# Accuracy\n","accuracy = accuracy_score(y_test_ADHD, y_pred)\n","print(f\"Validation Accuracy: {accuracy:.4f}\")\n","\n","# Weighted F1 Score\n","f1 = f1_score(y_test_ADHD, y_pred, average='weighted')\n","print(f\"Weighted F1 Score: {f1:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"yKUJFZpen-s4"},"source":["### Sex_f - hybrid gradient boosting trees"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CG4DjuWsq1jD"},"outputs":[],"source":["df = pd.merge(train_categorical, train_solutions, on='participant_id')\n","\n","participant_ids = df['participant_id']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6O2vLa9q6Dh"},"outputs":[],"source":["#fill missing NA values\n","df.fillna({'PreInt_Demos_Fam_Child_Ethnicity':df['PreInt_Demos_Fam_Child_Ethnicity'].mean()}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1742664297560,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"eAWyuQSV4sGW","outputId":"85ea0f3c-478f-48c0-9486-0cad24ad7acb"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBasic_Demos_Enroll_Year\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBasic_Demos_Study_Site\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ePreInt_Demos_Fam_Child_Ethnicity\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003ePreInt_Demos_Fam_Child_Race\u003c/th\u003e\n","      \u003ctd\u003e54\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eMRI_Track_Scan_Location\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBarratt_Barratt_P1_Edu\u003c/th\u003e\n","      \u003ctd\u003e15\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBarratt_Barratt_P1_Occ\u003c/th\u003e\n","      \u003ctd\u003e31\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBarratt_Barratt_P2_Edu\u003c/th\u003e\n","      \u003ctd\u003e198\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eBarratt_Barratt_P2_Occ\u003c/th\u003e\n","      \u003ctd\u003e222\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\u003cbr\u003e\u003clabel\u003e\u003cb\u003edtype:\u003c/b\u003e int64\u003c/label\u003e"],"text/plain":["Basic_Demos_Enroll_Year               0\n","Basic_Demos_Study_Site                0\n","PreInt_Demos_Fam_Child_Ethnicity      0\n","PreInt_Demos_Fam_Child_Race          54\n","MRI_Track_Scan_Location               3\n","Barratt_Barratt_P1_Edu               15\n","Barratt_Barratt_P1_Occ               31\n","Barratt_Barratt_P2_Edu              198\n","Barratt_Barratt_P2_Occ              222\n","dtype: int64"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["X.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"elapsed":28,"status":"error","timestamp":1742664280342,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"8mgzgdks50hN","outputId":"5c3be3a2-8909-468e-fa25-401c60fc0a3c"},"outputs":[{"ename":"ValueError","evalue":"Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-61-bb56a7ccc20f\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 7\u001b[0;31m \u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--\u003e 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-\u003e 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 99\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 157\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--\u003e 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}],"source":["X = df.drop(columns=['Sex_F', 'ADHD_Outcome', 'participant_id']) #drop ADHD\n","y = df['Sex_F']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"Bw-iwZguuf7c"},"source":["Best parameters: {'learning_rate': 0.05, 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500} Validation accuracy: 0.6213991769547325"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4785,"status":"ok","timestamp":1742245439717,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"fXp__1zWrUPD","outputId":"4e3904e0-2a01-4796-cd43-0c929f835fee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.6337\n","Weighted F1 Score: 0.6435\n"]}],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","# Initialize Gradient Boosting Classifier with best parameters\n","gbdt_cat_female = GradientBoostingClassifier(\n","    learning_rate=0.05,\n","    max_depth=7,\n","    min_samples_leaf=1,\n","    min_samples_split=2,\n","    n_estimators=500,\n","    random_state=42\n",")\n","\n","# Train the model\n","gbdt_cat_female.fit(X_train_resampled, y_train_resampled)\n","\n","# Predict on test set\n","y_pred = gbdt_cat_female.predict(X_test)\n","\n","# Evaluate performance\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","# Print results\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","print(f\"Weighted F1 Score: {f1:.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"WfkNVzW3hlrL"},"source":["##Quantitative Data Prep\n"]},{"cell_type":"markdown","metadata":{"id":"rLKVNHpVuXLL"},"source":["### ADHD - Gradient Boosted DT\n","\n","{'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1742245468767,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"JgaBxerx6rWk","outputId":"a00428fb-0ed6-48ce-e650-96db7fa6303b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gradient Boosting Accuracy: 0.7942\n","Weighted F1 Score: 0.7735\n"]}],"source":["# Combine the quantitative data with the ADHD_Outcome labels\n","train_data = pd.merge(train_quantitative, train_solutions, on='participant_id')\n","\n","# Separate features (X) and target variable (y)\n","X = train_data.drop(['participant_id', 'Sex_F', 'ADHD_Outcome', 'MRI_Track_Age_at_Scan'], axis=1)\n","y = train_data['ADHD_Outcome']\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Initialize and train the Gradient Boosting Classifier\n","gbdt_quant_ADHD = GradientBoostingClassifier(\n","    learning_rate=0.01,\n","    max_depth=3,\n","    min_samples_leaf=1,\n","    min_samples_split=2,\n","    n_estimators=100,\n","    random_state=42\n",")\n","\n","gbdt_quant_ADHD.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = gbdt_quant_ADHD.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Gradient Boosting Accuracy: {accuracy:.4f}')\n","\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","print(f\"Weighted F1 Score: {f1:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"rp7fEFx5uH-9"},"source":["### Sex_f - Optuna Model\n","\n","'n_estimators': 150, 'learning_rate': 0.08374413872051761, 'max_depth': 4\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":4590,"status":"ok","timestamp":1742245478063,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"4OIj21pi7ihF","outputId":"747b5d04-2267-4aa1-dedc-fbfa1040d96a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic\u003e=1.5.0 (from optuna)\n","  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy\u003e=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic\u003e=1.5.0-\u003eoptuna)\n","  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions\u003e=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy\u003e=1.4.2-\u003eoptuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe\u003e=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako-\u003ealembic\u003e=1.5.0-\u003eoptuna) (3.0.2)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"]}],"source":["pip install optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":5954,"status":"ok","timestamp":1742245485970,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"2vr21amC8TDi","outputId":"cf4fa9c9-6881-4843-fefe-d59cc1f49c8d"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-03-17 21:04:40,002] A new study created in memory with name: no-name-0c5f6b3a-1f6a-4560-883d-3185424c3316\n","[I 2025-03-17 21:04:40,091] Trial 0 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 250, 'learning_rate': 0.13400074853499278, 'max_depth': 6}. Best is trial 0 with value: 0.2962962962962963.\n","[I 2025-03-17 21:04:40,203] Trial 1 finished with value: 0.28395061728395066 and parameters: {'n_estimators': 200, 'learning_rate': 0.057333729558506574, 'max_depth': 4}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,251] Trial 2 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 100, 'learning_rate': 0.1663484207562276, 'max_depth': 3}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,301] Trial 3 finished with value: 0.29218106995884774 and parameters: {'n_estimators': 200, 'learning_rate': 0.16941702457235555, 'max_depth': 5}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,389] Trial 4 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 200, 'learning_rate': 0.0580976826006188, 'max_depth': 3}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,458] Trial 5 finished with value: 0.30452674897119336 and parameters: {'n_estimators': 100, 'learning_rate': 0.12240713523998821, 'max_depth': 4}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,563] Trial 6 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 50, 'learning_rate': 0.0650263243856644, 'max_depth': 6}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,752] Trial 7 finished with value: 0.2880658436213992 and parameters: {'n_estimators': 150, 'learning_rate': 0.04990239072334814, 'max_depth': 5}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,803] Trial 8 finished with value: 0.345679012345679 and parameters: {'n_estimators': 200, 'learning_rate': 0.176308435854626, 'max_depth': 6}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,861] Trial 9 finished with value: 0.28395061728395066 and parameters: {'n_estimators': 200, 'learning_rate': 0.0754959967822533, 'max_depth': 3}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:40,940] Trial 10 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 250, 'learning_rate': 0.03246622164947062, 'max_depth': 7}. Best is trial 1 with value: 0.28395061728395066.\n","[I 2025-03-17 21:04:41,076] Trial 11 finished with value: 0.2716049382716049 and parameters: {'n_estimators': 150, 'learning_rate': 0.08631509872789797, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,216] Trial 12 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 150, 'learning_rate': 0.01329409454219583, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,326] Trial 13 finished with value: 0.28395061728395066 and parameters: {'n_estimators': 100, 'learning_rate': 0.08846051189627713, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,442] Trial 14 finished with value: 0.27572016460905346 and parameters: {'n_estimators': 150, 'learning_rate': 0.10209492571441559, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,522] Trial 15 finished with value: 0.2716049382716049 and parameters: {'n_estimators': 150, 'learning_rate': 0.10589441410598806, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,611] Trial 16 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 50, 'learning_rate': 0.14060232839987716, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,683] Trial 17 finished with value: 0.31275720164609055 and parameters: {'n_estimators': 100, 'learning_rate': 0.19819822540954043, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,784] Trial 18 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 150, 'learning_rate': 0.10448720576952264, 'max_depth': 7}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,874] Trial 19 finished with value: 0.2880658436213992 and parameters: {'n_estimators': 100, 'learning_rate': 0.08727946296663025, 'max_depth': 6}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:41,973] Trial 20 finished with value: 0.29218106995884774 and parameters: {'n_estimators': 150, 'learning_rate': 0.11438210601266513, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,044] Trial 21 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 150, 'learning_rate': 0.09908006792341634, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,149] Trial 22 finished with value: 0.2716049382716049 and parameters: {'n_estimators': 150, 'learning_rate': 0.129077376605445, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,250] Trial 23 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 150, 'learning_rate': 0.14454221785650873, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,307] Trial 24 finished with value: 0.28395061728395066 and parameters: {'n_estimators': 150, 'learning_rate': 0.12598852703974417, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,388] Trial 25 finished with value: 0.3168724279835391 and parameters: {'n_estimators': 200, 'learning_rate': 0.15568042813448713, 'max_depth': 6}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,512] Trial 26 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 100, 'learning_rate': 0.08606491806112063, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,585] Trial 27 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 200, 'learning_rate': 0.11734781768131011, 'max_depth': 3}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,698] Trial 28 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 100, 'learning_rate': 0.07533716696535053, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,792] Trial 29 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 250, 'learning_rate': 0.13359720867637714, 'max_depth': 6}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,918] Trial 30 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 150, 'learning_rate': 0.037224190796686485, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:42,998] Trial 31 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 150, 'learning_rate': 0.09929155259768353, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,091] Trial 32 finished with value: 0.29218106995884774 and parameters: {'n_estimators': 150, 'learning_rate': 0.10682554266758632, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,191] Trial 33 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 150, 'learning_rate': 0.13027158330785898, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,274] Trial 34 finished with value: 0.279835390946502 and parameters: {'n_estimators': 150, 'learning_rate': 0.15057508197213604, 'max_depth': 3}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,391] Trial 35 finished with value: 0.3004115226337448 and parameters: {'n_estimators': 200, 'learning_rate': 0.07507804644304689, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,485] Trial 36 finished with value: 0.29218106995884774 and parameters: {'n_estimators': 100, 'learning_rate': 0.10943620349482586, 'max_depth': 3}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,596] Trial 37 finished with value: 0.2880658436213992 and parameters: {'n_estimators': 200, 'learning_rate': 0.09110281657227302, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,702] Trial 38 finished with value: 0.30452674897119336 and parameters: {'n_estimators': 100, 'learning_rate': 0.11740480585884223, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,848] Trial 39 finished with value: 0.27572016460905346 and parameters: {'n_estimators': 200, 'learning_rate': 0.06727257233044244, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:43,971] Trial 40 finished with value: 0.279835390946502 and parameters: {'n_estimators': 50, 'learning_rate': 0.09657812898716603, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:44,163] Trial 41 finished with value: 0.29218106995884774 and parameters: {'n_estimators': 200, 'learning_rate': 0.06469975339082032, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:44,395] Trial 42 finished with value: 0.2716049382716049 and parameters: {'n_estimators': 200, 'learning_rate': 0.05055788089834406, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:44,519] Trial 43 finished with value: 0.30452674897119336 and parameters: {'n_estimators': 250, 'learning_rate': 0.05161664289367352, 'max_depth': 6}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:44,774] Trial 44 finished with value: 0.29218106995884774 and parameters: {'n_estimators': 150, 'learning_rate': 0.034612776421578964, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:44,944] Trial 45 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 150, 'learning_rate': 0.015283170064927146, 'max_depth': 6}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:45,253] Trial 46 finished with value: 0.279835390946502 and parameters: {'n_estimators': 200, 'learning_rate': 0.044556259283206584, 'max_depth': 4}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:45,476] Trial 47 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 150, 'learning_rate': 0.02359344355966495, 'max_depth': 3}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:45,565] Trial 48 finished with value: 0.2962962962962963 and parameters: {'n_estimators': 150, 'learning_rate': 0.16514324273134628, 'max_depth': 5}. Best is trial 11 with value: 0.2716049382716049.\n","[I 2025-03-17 21:04:45,731] Trial 49 finished with value: 0.31275720164609055 and parameters: {'n_estimators': 250, 'learning_rate': 0.125762132956982, 'max_depth': 6}. Best is trial 11 with value: 0.2716049382716049.\n"]},{"name":"stdout","output_type":"stream","text":["Best Model Accuracy (Optuna): 0.7283950617283951\n"]}],"source":["# most code from geeks for geeks\n","import optuna\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# this code is taken from above ################\n","# Combine the quantitative data with the ADHD_Outcome labels\n","train_data = pd.merge(train_quantitative, train_solutions, on='participant_id')\n","\n","# Separate features (X) and target variable (y)\n","X = train_data.drop(['participant_id', 'Sex_F', 'ADHD_Outcome', 'MRI_Track_Age_at_Scan'], axis=1)\n","y = train_data['Sex_F']\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scale numerical features\n","scaler2 = StandardScaler()\n","X_train = scaler2.fit_transform(X_train)\n","X_test = scaler2.transform(X_test)\n","###################################################\n","\n","def objective(trial):\n","    param_space = {\n","        'n_estimators': trial.suggest_int('n_estimators', 50, 250, step=50),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n","        'max_depth': trial.suggest_int('max_depth', 3, 7),\n","    }\n","\n","    gb_model = GradientBoostingClassifier(**param_space, validation_fraction=0.1, n_iter_no_change=5, random_state=42)\n","\n","    gb_model.fit(X_train, y_train)\n","\n","    y_pred = gb_model.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    return 1.0 - accuracy\n","\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=50)\n","\n","best_params_optuna = study.best_params\n","best_model_optuna = GradientBoostingClassifier(**best_params_optuna, validation_fraction=0.1, n_iter_no_change=5, random_state=42)\n","best_model_optuna.fit(X_train, y_train)\n","\n","y_pred_best_optuna = best_model_optuna.predict(X_test)\n","\n","accuracy_best_optuna = accuracy_score(y_test, y_pred_best_optuna)\n","\n","print(f\"Best Model Accuracy (Optuna): {accuracy_best_optuna}\")\n"]},{"cell_type":"markdown","metadata":{"id":"VH7wRSO99Awj"},"source":["For some reason I am getting that the best parameters are {'n_estimators': 200, 'learning_rate': 0.11596113051499049, 'max_depth': 4} ?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86,"status":"ok","timestamp":1742245490196,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"3ciaxdB47YP9","outputId":"e04eab78-d0a9-4c0a-f67b-cfc083d89ab4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Model Accuracy (Optuna): 0.7325102880658436\n","Weighted F1 Score: 0.2882\n"]}],"source":["import optuna\n","# most code from geeks for geeks\n","\n","\n","\n","# this code is taken from above ################\n","# Combine the quantitative data with the ADHD_Outcome labels\n","train_data = pd.merge(train_quantitative, train_solutions, on='participant_id')\n","\n","# Separate features (X) and target variable (y)\n","X = train_data.drop(['participant_id', 'Sex_F', 'ADHD_Outcome', 'MRI_Track_Age_at_Scan'], axis=1)\n","y = train_data['Sex_F']\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scale numerical features\n","scaler2 = StandardScaler()\n","X_train = scaler2.fit_transform(X_train)\n","X_test = scaler2.transform(X_test)\n","###################################################\n","\n","gbdt_quant_female = GradientBoostingClassifier(\n","    learning_rate=0.11596113051499049,\n","    max_depth=4,\n","    n_estimators=200,\n","    validation_fraction=0.1,\n","    n_iter_no_change=5,\n","    random_state=42\n",")\n","gbdt_quant_female.fit(X_train, y_train)\n","\n","y_pred_best_optuna = gbdt_quant_female.predict(X_test)\n","\n","accuracy_best_optuna = accuracy_score(y_test, y_pred_best_optuna)\n","\n","print(f\"Best Model Accuracy (Optuna): {accuracy_best_optuna}\")\n","\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","print(f\"Weighted F1 Score: {f1:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H8wbNT5bhn8B"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"SypWyOMOhoX1"},"source":["## FCM Data Prep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4uu9CkeXCjZs"},"outputs":[],"source":["!pip install torch-geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZISl9UK_aXC"},"outputs":[],"source":["#reset graph_fcm before running below cell\n","graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n","\n","\n","import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.data import Data\n","import numpy as np  # Ensure NumPy is imported\n","\n","# Check if GPU is available and set the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n","# Remove 'Sex_F' column\n","graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n","\n","# Prepare data for PyTorch Geometric\n","connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n","features = graph_fcm[connectivity_columns].values\n","labels = graph_fcm['ADHD_Outcome'].values\n","\n","# Create an adjacency matrix (replace with actual adjacency if available)\n","num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n","adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5))) #LITERALLY JUST DIVIDED IN HALF SO ITS NOT FULLY CONNECTED ITS HALF CONNECTED?\n","np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n","\n","# Convert to PyTorch tensors and move to device\n","data = Data(\n","    x=torch.tensor(features, dtype=torch.float32).to(device),\n","    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n","    y=torch.tensor(labels, dtype=torch.long).to(device)\n",")\n","\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = GCNConv(in_channels, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","\n","# Hyperparameters\n","in_channels = data.num_features\n","hidden_channels = 64\n","out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n","learning_rate = 0.01\n","epochs = 200\n","\n","# Model, optimizer, and loss function\n","model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n","optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Train the model\n","model_adhd.train()\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    out = model_adhd(data.x, data.edge_index)\n","    loss = criterion(out, data.y)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 50 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n","\n","# Evaluation\n","model_adhd.eval()\n","_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n","correct = float(pred.eq(data.y).sum().item())\n","acc = correct / len(data.y)\n","print(f\"Accuracy: {acc:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ty_kReOf_gCE"},"outputs":[],"source":["#reset graph_fcm before running below cell\n","graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n","\n","\n","import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.data import Data\n","import numpy as np  # Ensure NumPy is imported\n","\n","# Check if GPU is available and set the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n","# Remove 'Sex_F' column\n","graph_fcm = graph_fcm.drop('ADHD_Outcome', axis=1)\n","\n","# Prepare data for PyTorch Geometric\n","connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'Sex_F']]\n","features = graph_fcm[connectivity_columns].values\n","labels = graph_fcm['Sex_F'].values\n","\n","# Create an adjacency matrix (replace with actual adjacency if available)\n","num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n","adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5)))\n","np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n","\n","# Convert to PyTorch tensors and move to device\n","data = Data(\n","    x=torch.tensor(features, dtype=torch.float32).to(device),\n","    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n","    y=torch.tensor(labels, dtype=torch.long).to(device)\n",")\n","\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = GCNConv(in_channels, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","\n","# Hyperparameters\n","in_channels = data.num_features\n","hidden_channels = 64\n","out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n","learning_rate = 0.01\n","epochs = 200\n","\n","# Model, optimizer, and loss function\n","model_f = GCN(in_channels, hidden_channels, out_channels).to(device)\n","optimizer = torch.optim.Adam(model_f.parameters(), lr=learning_rate)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Train the model\n","model_f.train()\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    out = model_f(data.x, data.edge_index)\n","    loss = criterion(out, data.y)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 50 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n","\n","# Evaluation\n","model_f.eval()\n","_, pred = model_f(data.x, data.edge_index).max(dim=1)\n","correct = float(pred.eq(data.y).sum().item())\n","acc = correct / len(data.y)\n","print(f\"Accuracy: {acc:.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"9DFCSDrS_TBf"},"source":["#Ensemble Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBn56P3uBThg"},"outputs":[],"source":["df = pd.merge(train_categorical, train_solutions, on='participant_id')\n","participant_ids = df['participant_id']\n","\n","df.fillna({'PreInt_Demos_Fam_Child_Ethnicity':df['PreInt_Demos_Fam_Child_Ethnicity'].mean()}, inplace = True)\n","\n","X = df.drop(columns=['Sex_F', 'participant_id'])\n","y = df['Sex_F']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=42)\n","X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n","\n","X_train_ADHD = X_train_resampled.drop(columns=['ADHD_Outcome'])\n","y_train_ADHD = X_train_resampled['ADHD_Outcome']\n","x_test_ADHD = X_test.drop(columns=['ADHD_Outcome'])\n","y_test_ADHD = X_test['ADHD_Outcome']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1tXNaBeVBhe1"},"outputs":[],"source":["df = pd.merge(train_categorical, train_solutions, on='participant_id')\n","participant_ids = df['participant_id']\n","\n","df.fillna({'PreInt_Demos_Fam_Child_Ethnicity':df['PreInt_Demos_Fam_Child_Ethnicity'].mean()}, inplace = True)\n","\n","X = df.drop(columns=['Sex_F', 'ADHD_Outcome', 'participant_id']) #drop ADHD\n","y = df['Sex_F']\n","\n","X_train, X_test_cat_female, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n","X_train_resampled_female, y_train_resampled = smote.fit_resample(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbpR69DzCCdw"},"outputs":[],"source":["train_data = pd.merge(train_quantitative, train_solutions, on='participant_id')\n","\n","X = train_data.drop(['participant_id', 'Sex_F', 'ADHD_Outcome', 'MRI_Track_Age_at_Scan'], axis=1)\n","y = train_data['Sex_F']\n","\n","X_train_quant, X_test_quant, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1741579134310,"user":{"displayName":"Kayla DePalma","userId":"12687531437102009769"},"user_tz":240},"id":"645Lv5mgAIxM","outputId":"8642cccf-55cb-430c-d50f-3469aa7e2224"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n"]}],"source":["# Get base model predictions\n","pred_ADHD_1 = gbdt_cat_ADHD.predict_proba(X_train_ADHD)[:, 1]  # Probability of ADHD\n","pred_ADHD_2 = gbdt_quant_ADHD.predict_proba(X_train_quant)[:, 1]\n","\n","pred_gender_1 = gbdt_cat_female.predict_proba(X_train_resampled_female)[:, 1]  # Probability of being male or female\n","pred_gender_2 = gbdt_quant_female.predict_proba(X_train_quant)[:, 1]\n","\n","# Stack predictions as new features\n","meta_X_train_ADHD = np.column_stack((pred_ADHD_1, pred_ADHD_2[-688:]))\n","meta_X_train_female = np.column_stack((pred_gender_1[:970], pred_gender_2)) #I HAD TO CUT OFF THE FIRST MODEL BC THEY HAD DIFFERENT SIZES BUT THERE HAS TO BE A BETTER SOLUTION\n","\n","# Define meta-targets\n","meta_y_train_adhd = train_solutions['ADHD_Outcome']  # True ADHD labels\n","meta_y_train_gender = train_solutions['Sex_F']  # True Gender labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1741579136826,"user":{"displayName":"Kayla DePalma","userId":"12687531437102009769"},"user_tz":240},"id":"Foipk0yuA5cE","outputId":"5a7e09db-08ed-4d21-dacf-7462ed262320"},"outputs":[{"data":{"text/html":["\u003cstyle\u003e#sk-container-id-3 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: #000;\n","  --sklearn-color-text-muted: #666;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-3 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-3 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-3 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-3 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-3 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-3 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-3 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-3 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-3 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-3 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-3 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: flex;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","  align-items: start;\n","  justify-content: space-between;\n","  gap: 0.5em;\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label .caption {\n","  font-size: 0.6rem;\n","  font-weight: lighter;\n","  color: var(--sklearn-color-text-muted);\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-3 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-3 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-3 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-3 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-3 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-3 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 0.5em;\n","  text-align: center;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `\u003ca\u003e` HTML tag */\n","\n","#sk-container-id-3 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-3 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-3 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","\u003c/style\u003e\u003cdiv id=\"sk-container-id-3\" class=\"sk-top-container\"\u003e\u003cdiv class=\"sk-text-repr-fallback\"\u003e\u003cpre\u003eLogisticRegression()\u003c/pre\u003e\u003cb\u003eIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. \u003cbr /\u003eOn GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u003c/b\u003e\u003c/div\u003e\u003cdiv class=\"sk-container\" hidden\u003e\u003cdiv class=\"sk-item\"\u003e\u003cdiv class=\"sk-estimator fitted sk-toggleable\"\u003e\u003cinput class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked\u003e\u003clabel for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"\u003e\u003cdiv\u003e\u003cdiv\u003eLogisticRegression\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003ca class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\"\u003e?\u003cspan\u003eDocumentation for LogisticRegression\u003c/span\u003e\u003c/a\u003e\u003cspan class=\"sk-estimator-doc-link fitted\"\u003ei\u003cspan\u003eFitted\u003c/span\u003e\u003c/span\u003e\u003c/div\u003e\u003c/label\u003e\u003cdiv class=\"sk-toggleable__content fitted\"\u003e\u003cpre\u003eLogisticRegression()\u003c/pre\u003e\u003c/div\u003e \u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e"],"text/plain":["LogisticRegression()"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","# Meta-model for ADHD\n","meta_model_adhd = LogisticRegression()\n","meta_model_adhd.fit(meta_X_train_ADHD, meta_y_train_adhd[-688:])\n","\n","# Meta-model for Gender\n","meta_model_gender = LogisticRegression()\n","meta_model_gender.fit(meta_X_train_female, meta_y_train_gender[:970])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70,"status":"ok","timestamp":1741579150311,"user":{"displayName":"Kayla DePalma","userId":"12687531437102009769"},"user_tz":240},"id":"m7PtuFXeF51t","outputId":"d51ca7a8-e583-4ac3-ebad-c4280a5178bc"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n"]}],"source":["# Get base model predictions on test data\n","pred_adhd_1_test = gbdt_cat_ADHD.predict_proba(x_test_ADHD)[:, 1]\n","pred_adhd_2_test = gbdt_quant_ADHD.predict_proba(X_test_quant)[:, 1]\n","\n","pred_gender_1_test = gbdt_cat_female.predict_proba(X_test_cat_female)[:, 1]\n","pred_gender_2_test = gbdt_quant_female.predict_proba(X_test_quant)[:, 1]\n","\n","# Stack predictions as new features\n","meta_X_test_ADHD = np.column_stack((pred_adhd_1_test, pred_adhd_2_test))\n","meta_X_test_gender = np.column_stack((pred_gender_1_test, pred_gender_2_test))\n","\n","\n","# Meta-model predictions\n","final_pred_adhd = meta_model_adhd.predict(meta_X_test_ADHD)\n","final_pred_gender = meta_model_gender.predict(meta_X_test_gender)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1741579151925,"user":{"displayName":"Kayla DePalma","userId":"12687531437102009769"},"user_tz":240},"id":"wDC8mevkIVNR","outputId":"59b135da-b71e-43c2-aec9-e0e5487e9b07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy for ADHD prediction: 0.2674897119341564\n","F1 Score for ADHD prediction: 0.11290150179039067\n","Accuracy for Gender prediction: 0.7037037037037037\n","F1 Score for Gender prediction: 0.5813204508856683\n"]}],"source":["# Accuracy for ADHD prediction\n","accuracy_adhd = accuracy_score(y_test_ADHD, final_pred_adhd)\n","print(f\"Accuracy for ADHD prediction: {accuracy_adhd}\")\n","\n","# F1 Score for ADHD prediction\n","f1_adhd = f1_score(y_test_ADHD, final_pred_adhd, average='weighted')\n","print(f\"F1 Score for ADHD prediction: {f1_adhd}\")\n","\n","# Accuracy for Gender prediction\n","accuracy_gender = accuracy_score(y_test, final_pred_gender)\n","print(f\"Accuracy for Gender prediction: {accuracy_gender}\")\n","\n","# F1 Score for Gender prediction\n","f1_gender = f1_score(y_test, final_pred_gender, average='weighted')\n","print(f\"F1 Score for Gender prediction: {f1_gender}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6qcgDFEKAhd"},"outputs":[],"source":["test_categorical = pd.read_excel(\"/content/TEST_CATEGORICAL.xlsx\")\n","test_quantitative = pd.read_excel(\"/content/TEST_QUANTITATIVE_METADATA.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KwK-EV8jK2Oe"},"outputs":[],"source":["X_test_final_quant = test_quantitative.drop(['participant_id', 'MRI_Track_Age_at_Scan'], axis=1)\n","X_test_final_quant = X_test_final_quant.apply(lambda col: col.fillna(col.mean()), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpIFDroNLPR9"},"outputs":[],"source":["X_test_final_cat = test_categorical.drop(['participant_id'], axis=1)\n","X_test_final_cat = X_test_final_cat.apply(lambda col: col.fillna(col.mode()[0]), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1741579159727,"user":{"displayName":"Kayla DePalma","userId":"12687531437102009769"},"user_tz":240},"id":"RQfS-xmNLFh7","outputId":"b56256bd-df13-40d1-c797-ec0d6e451cd2"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n","  warnings.warn(\n"]}],"source":["# Get base model predictions on test data\n","pred_adhd_1_test = gbdt_cat_ADHD.predict_proba(X_test_final_cat)[:, 1]\n","pred_adhd_2_test = gbdt_quant_ADHD.predict_proba(X_test_final_quant)[:, 1]\n","\n","pred_gender_1_test = gbdt_cat_female.predict_proba(X_test_final_cat)[:, 1]\n","pred_gender_2_test = gbdt_quant_female.predict_proba(X_test_final_quant)[:, 1]\n","\n","# Stack predictions as new features\n","meta_X_test_ADHD = np.column_stack((pred_adhd_1_test, pred_adhd_2_test))\n","meta_X_test_gender = np.column_stack((pred_gender_1_test, pred_gender_2_test))\n","\n","# Meta-model predictions\n","final_pred_adhd = meta_model_adhd.predict(meta_X_test_ADHD)\n","final_pred_gender = meta_model_gender.predict(meta_X_test_gender)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1741579258536,"user":{"displayName":"Kayla DePalma","userId":"12687531437102009769"},"user_tz":240},"id":"uu1t7ECkNaJR","outputId":"6398761b-c43e-4265-fff3-8273870f34b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy for ADHD prediction: 0.2674897119341564\n","F1 Score for ADHD prediction: 0.11290150179039067\n","Accuracy for Gender prediction: 0.7037037037037037\n","F1 Score for Gender prediction: 0.5813204508856683\n"]}],"source":["# Accuracy for ADHD prediction\n","accuracy_adhd = accuracy_score(y_test_ADHD, final_pred_adhd[:243])\n","print(f\"Accuracy for ADHD prediction: {accuracy_adhd}\")\n","\n","# F1 Score for ADHD prediction\n","f1_adhd = f1_score(y_test_ADHD, final_pred_adhd[:243], average='weighted')\n","print(f\"F1 Score for ADHD prediction: {f1_adhd}\")\n","\n","# Accuracy for Gender prediction\n","accuracy_gender = accuracy_score(y_test, final_pred_gender[:243])\n","print(f\"Accuracy for Gender prediction: {accuracy_gender}\")\n","\n","# F1 Score for Gender prediction\n","f1_gender = f1_score(y_test, final_pred_gender[:243], average='weighted')\n","print(f\"F1 Score for Gender prediction: {f1_gender}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1741579371760,"user":{"displayName":"Kayla DePalma","userId":"12687531437102009769"},"user_tz":240},"id":"Th-NQwfBJYOA","outputId":"01408262-c859-4dc3-98c8-5446614a3bb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["   participant_id  ADHD_Outcome  Sex_F\n","0    Cfwaf5FX7jWK             0      0\n","1    vhGrzmvA3Hjq             0      0\n","2    ULliyEXjy4OV             0      0\n","3    LZfeAb1xMtql             0      0\n","4    EnFOUv0YK1RG             0      0\n","5    3VbkvJ22j9Fu             0      0\n","6    PRKZcnOgqcuk             0      0\n","7    DuVUuyMZi5qV             0      0\n","8    uM4etVLZrgMg             0      0\n","9    BpzyExrET5ta             0      0\n","10   sAqeb6F4lz97             0      0\n","11   u7XOOvHirIx7             0      0\n","12   aEPm4bEQvbYi             0      0\n","13   Fj9A5PWsIWKT             0      0\n","14   19mb5yGJigtw             0      0\n","15   v1nMpCoLGU0V             0      0\n","16   hRPuz4zpsEbw             0      0\n","17   mT8A6xa1O4Ro             0      0\n","18   4QBTjDoVpVt6             0      0\n","19   0X2H4LroxZcw             0      0\n","20   9CH7UxXuznUa             0      0\n","21   nU73zzjTnr4A             0      0\n","22   uEZHGukIUQ0k             0      0\n","23   jCzQwkpfgZyQ             0      0\n","24   Ljvrs76QJuI5             0      0\n","25   IbF3zW0Wbx4Q             0      0\n","26   UHnGiDNksa0x             0      0\n","27   yYjiJsx8PM48             0      0\n","28   1j28gfEoCQ3o             0      0\n","29   dC5XvD5A3tqo             0      0\n"]}],"source":["participant_ids = test_quantitative['participant_id']\n","\n","# Create a dictionary to hold the data\n","data = {\n","    'participant_id': participant_ids,\n","    'ADHD_Outcome': final_pred_adhd,\n","    'Sex_F': final_pred_gender\n","}\n","\n","# Create a Pandas DataFrame\n","df = pd.DataFrame(data)\n","\n","# Save the DataFrame to a CSV file\n","df.to_csv('predictions.csv', index=False)\n","\n","# Print the first few rows to verify (optional)\n","print(df.head(30))\n"]},{"cell_type":"markdown","metadata":{"id":"pvYHnm5nOF06"},"source":["Predicting everything is 0 ?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":10104,"status":"ok","timestamp":1742313251971,"user":{"displayName":"Jannatul Nayeem","userId":"09786473422494177819"},"user_tz":240},"id":"W6BMeoMa9NVJ","outputId":"12f86106-9e67-421f-9017-6b320093005a"},"outputs":[{"name":"stdout","output_type":"stream","text":["ADHD: 304, No ADHD: 0\n","Female: 111, Male: 193\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_ee950986-bb46-4e26-9d78-84125e9e71f3\", \"predictions.csv\", 5202)"],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  participant_id  ADHD_Outcome  Sex_F\n","0   Cfwaf5FX7jWK             1      0\n","1   vhGrzmvA3Hjq             1      1\n","2   ULliyEXjy4OV             1      0\n","3   LZfeAb1xMtql             1      1\n","4   EnFOUv0YK1RG             1      0\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.data import Data\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","\n","# Step 1: Load the test data\n","test_categorical = pd.read_excel('TEST/TEST_CATEGORICAL.xlsx')\n","test_quantitative = pd.read_excel('TEST/TEST_QUANTITATIVE_METADATA.xlsx')\n","test_fcm = pd.read_csv('TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n","\n","# Step 2: Ensure test data has the same preprocessing as training data\n","# Get the same columns as used in training\n","cat_columns = [col for col in test_categorical.columns if col != 'participant_id']\n","quant_columns = [col for col in test_quantitative.columns if col != 'participant_id' and col != 'MRI_Track_Age_at_Scan']\n","fcm_columns = [col for col in test_fcm.columns if col != 'participant_id']\n","\n","# Extract features from test data\n","test_cat_features = test_categorical[cat_columns]\n","test_quant_features = test_quantitative[quant_columns]\n","test_fcm_features = test_fcm[fcm_columns]\n","\n","# Step 3: Apply imputation to handle missing values\n","# For categorical data\n","cat_imputer = SimpleImputer(strategy='most_frequent')\n","cat_imputer.fit(test_cat_features)\n","test_cat_imputed = cat_imputer.transform(test_cat_features)\n","\n","# For quantitative data\n","quant_imputer = SimpleImputer(strategy='mean')\n","quant_imputer.fit(test_quant_features)\n","test_quant_imputed = quant_imputer.transform(test_quant_features)\n","\n","# Scale the quantitative data\n","scaler = StandardScaler()\n","scaler.fit(test_quant_imputed)\n","test_quant_scaled = scaler.transform(test_quant_imputed)\n","\n","# For FCM data\n","fcm_imputer = SimpleImputer(strategy='mean')\n","fcm_imputer.fit(test_fcm_features)\n","test_fcm_imputed = fcm_imputer.transform(test_fcm_features)\n","\n","# Step 4: Prepare FCM data for PyTorch Geometric\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_test_nodes = test_fcm_imputed.shape[0]\n","test_adjacency_matrix = np.ones(((int)(num_test_nodes/2.5), (int)(num_test_nodes/2.5)))\n","np.fill_diagonal(test_adjacency_matrix, 0)  # No self-loops\n","\n","# Convert to PyTorch Geometric format\n","test_fcm_data = Data(\n","    x=torch.tensor(test_fcm_imputed, dtype=torch.float32).to(device),\n","    edge_index=torch.tensor(np.array(np.where(test_adjacency_matrix)), dtype=torch.long).to(device)\n",")\n","\n","# Step 5: Make predictions using each model\n","# Categorical model predictions for ADHD\n","cat_adhd_pred = gbdt_cat_ADHD.predict(test_cat_imputed)\n","\n","# Categorical model predictions for Sex_F\n","cat_sex_pred = gbdt_cat_female.predict(test_cat_imputed)\n","\n","# Quantitative model predictions for ADHD\n","quant_adhd_pred = gbdt_quant_ADHD.predict(test_quant_scaled)\n","\n","# Quantitative model predictions for Sex_F\n","quant_sex_pred = gbdt_quant_female.predict(test_quant_scaled)\n","\n","# FCM model predictions for ADHD\n","model_adhd.eval()\n","with torch.no_grad():\n","    fcm_adhd_logits = model_adhd(test_fcm_data.x, test_fcm_data.edge_index)\n","    _, fcm_adhd_pred = fcm_adhd_logits.max(dim=1)\n","    fcm_adhd_pred = fcm_adhd_pred.cpu().numpy()\n","\n","# FCM model predictions for Sex_F\n","model_f.eval()\n","with torch.no_grad():\n","    fcm_sex_logits = model_f(test_fcm_data.x, test_fcm_data.edge_index)\n","    _, fcm_sex_pred = fcm_sex_logits.max(dim=1)\n","    fcm_sex_pred = fcm_sex_pred.cpu().numpy()\n","\n","# Step 6: Create ensemble predictions using majority voting\n","# For ADHD prediction\n","adhd_votes = np.vstack([cat_adhd_pred, quant_adhd_pred, fcm_adhd_pred])\n","adhd_majority = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=adhd_votes)\n","\n","# For Sex_F prediction\n","sex_votes = np.vstack([cat_sex_pred, quant_sex_pred, fcm_sex_pred])\n","sex_majority = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=sex_votes)\n","\n","# Step 7: Create final prediction dataframe\n","final_pred = pd.DataFrame({\n","    'participant_id': test_fcm['participant_id'].values,\n","    'ADHD_Outcome': adhd_majority,\n","    'Sex_F': sex_majority\n","})\n","\n","# Print summary statistics\n","adhd_count = final_pred['ADHD_Outcome'].sum()\n","no_adhd_count = len(final_pred) - adhd_count\n","female_count = final_pred['Sex_F'].sum()\n","male_count = len(final_pred) - female_count\n","\n","print(f\"ADHD: {adhd_count}, No ADHD: {no_adhd_count}\")\n","print(f\"Female: {female_count}, Male: {male_count}\")\n","\n","# Save predictions to CSV\n","final_pred.to_csv('predictions.csv', index=False)\n","from google.colab import files\n","files.download('predictions.csv')\n","\n","# Verify the format\n","print(final_pred.head())"]},{"cell_type":"markdown","metadata":{"id":"qpnFgHmx_sHP"},"source":["Predicting all ADHD for some reason"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qu5yhNHCDPir"},"outputs":[],"source":["# Get probabilities from quantitative model (since it showed some variation)\n","quant_adhd_proba = gbdt_quant_ADHD.predict_proba(test_quant_scaled)[:, 1]\n","\n","# Instead of majority voting or all 1's, set a low threshold to get ~85-90% ADHD predictions\n","# Try a threshold of 0.5 or lower to get most but not all as ADHD\n","threshold = 0.4  # Adjust this value to control the percentage of ADHD predictions\n","adhd_pred = (quant_adhd_proba \u003e threshold).astype(int)\n","\n","# Calculate the percentage of ADHD predictions with this threshold\n","adhd_percent = np.mean(adhd_pred) * 100\n","print(f\"Threshold {threshold}: ADHD = {adhd_percent:.1f}% of participants\")\n","\n","# Alternative approach: Take the bottom N% by probability and set them to 0\n","# This gives you direct control over the percentage\n","percentage_nonADHD = 15  # Set this to control what percentage are predicted as non-ADHD\n","cutoff_value = np.percentile(quant_adhd_proba, percentage_nonADHD)\n","adhd_pred_alt = (quant_adhd_proba \u003e cutoff_value).astype(int)\n","adhd_percent_alt = np.mean(adhd_pred_alt) * 100\n","print(f\"Bottom {percentage_nonADHD}%: ADHD = {adhd_percent_alt:.1f}% of participants\")\n","\n","# Use the alternative approach for final predictions\n","final_pred = pd.DataFrame({\n","    'participant_id': test_fcm['participant_id'].values,\n","    'ADHD_Outcome': adhd_pred_alt,  # This will predict ADHD for 85% of participants\n","    'Sex_F': sex_majority  # Keep the sex predictions as they were\n","})\n","\n","# Print summary statistics\n","adhd_count = final_pred['ADHD_Outcome'].sum()\n","no_adhd_count = len(final_pred) - adhd_count\n","female_count = final_pred['Sex_F'].sum()\n","male_count = len(final_pred) - female_count\n","\n","print(f\"ADHD: {adhd_count}, No ADHD: {no_adhd_count}\")\n","print(f\"Female: {female_count}, Male: {male_count}\")\n","\n","# Save predictions to CSV\n","final_pred.to_csv('predictions.csv', index=False)\n","from google.colab import files\n","files.download('predictions.csv')\n","\n","# Verify the format\n","print(final_pred.head())"]},{"cell_type":"markdown","metadata":{"id":"vZhnXts3Sg-l"},"source":["got 0.66 from above"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}