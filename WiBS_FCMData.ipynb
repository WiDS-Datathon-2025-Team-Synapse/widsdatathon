{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXBCl4CI867v",
        "outputId": "09f7d205-f78b-4442-de2b-81ff5d6d5e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "widsdatathon2025.zip\n",
            "Archive:  widsdatathon2025.zip\n",
            "  inflating: Data Dictionary.xlsx    \n",
            "  inflating: SAMPLE_SUBMISSION.xlsx  \n",
            "  inflating: TEST/TEST_CATEGORICAL.xlsx  \n",
            "  inflating: TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv  \n",
            "  inflating: TEST/TEST_QUANTITATIVE_METADATA.xlsx  \n",
            "  inflating: TRAIN/TRAINING_SOLUTIONS.xlsx  \n",
            "  inflating: TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx  \n",
            "  inflating: TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv  \n",
            "  inflating: TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx  \n"
          ]
        }
      ],
      "source": [
        "#@title uploader\n",
        "file_id = \"1rVYGtWzw9s9Bw80-XaIN8gYBsBG79K8B\" #@param {type:\"string\"}\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Replace the assignment below with your file ID\n",
        "# to download a different file.\n",
        "#\n",
        "# A file ID looks like: 1gLBqEWEBQDYbKCDigHnUXNTkzl-OslSO\n",
        "\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, done = downloader.next_chunk()\n",
        "\n",
        "fileId = drive.CreateFile({'id': file_id }) #DRIVE_FILE_ID is file id example: 1iytA1n2z4go3uVCwE_vIKouTKyIDjEq\n",
        "print(fileId['title'])\n",
        "fileId.GetContentFile(fileId['title'])  # Save Drive file as a local file\n",
        "\n",
        "!unzip {fileId['title']}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading + imports"
      ],
      "metadata": {
        "id": "dKariRSZ9SHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I don't have this package so I'm installing it. If the cell below doesn't work\n",
        "# for you, you might have to run this before.\n",
        "!pip install geomstats"
      ],
      "metadata": {
        "id": "qeRX0HDd9_tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a40512-0222-40ee-f4eb-1fb0221855b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geomstats\n",
            "  Downloading geomstats-2.8.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: joblib>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.11/dist-packages (from geomstats) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from geomstats) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->geomstats) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->geomstats) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.1->geomstats) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->geomstats) (1.17.0)\n",
            "Downloading geomstats-2.8.0-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: geomstats\n",
            "Successfully installed geomstats-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geomstats.datasets.utils as data_utils\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DrwNFZnt9M1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd12a758-3bf3-44a2-e05c-5f3dc66ce787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3OW6eoCyU14",
        "outputId": "9e655391-0c81-421a-ed74-60861a915b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "i39a5Pk9VWSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6055cd9e-913f-4349-d0e8-ea870e6e5a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcm = pd.read_csv(\"TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
        "fcm_solutions = pd.read_excel(\"TRAIN/TRAINING_SOLUTIONS.xlsx\")"
      ],
      "metadata": {
        "id": "7hxAtZ4u9fqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "F3T5tRkNfdBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Exploration"
      ],
      "metadata": {
        "id": "i_x8pMcBzSxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fcm.shape"
      ],
      "metadata": {
        "id": "jR_NF3lm_N4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9b4c51-ca33-4e6e-bb07-037251886708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1213, 19901)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcm.describe()"
      ],
      "metadata": {
        "id": "0NPwOG3E_R_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "1a9e4114-44ab-43a1-e5ed-bdaf0f68b193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  0throw_4thcolumn  \\\n",
              "count       1213.000000       1213.000000       1213.000000       1213.000000   \n",
              "mean           0.060553          0.122315          0.060268          0.041287   \n",
              "std            0.064178          0.054026          0.057495          0.043491   \n",
              "min           -0.183279         -0.059932         -0.145566         -0.127827   \n",
              "25%            0.018482          0.086102          0.026548          0.014457   \n",
              "50%            0.058276          0.123220          0.061339          0.043246   \n",
              "75%            0.100103          0.154518          0.099056          0.068408   \n",
              "max            0.321522          0.390895          0.278429          0.189825   \n",
              "\n",
              "       0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  0throw_8thcolumn  \\\n",
              "count       1213.000000       1213.000000       1213.000000       1213.000000   \n",
              "mean           0.069722          0.091007          0.066852          0.000252   \n",
              "std            0.044222          0.049189          0.046864          0.049046   \n",
              "min           -0.072043         -0.079184         -0.105722         -0.164297   \n",
              "25%            0.042462          0.057614          0.036934         -0.031358   \n",
              "50%            0.067066          0.086494          0.067247          0.002549   \n",
              "75%            0.096504          0.119404          0.095117          0.031053   \n",
              "max            0.317500          0.316811          0.270018          0.168196   \n",
              "\n",
              "       0throw_9thcolumn  0throw_10thcolumn  ...  195throw_196thcolumn  \\\n",
              "count       1213.000000        1213.000000  ...           1213.000000   \n",
              "mean           0.014128          -0.002914  ...              0.011075   \n",
              "std            0.038205           0.042462  ...              0.049632   \n",
              "min           -0.137728          -0.148490  ...             -0.161666   \n",
              "25%           -0.010635          -0.030538  ...             -0.021376   \n",
              "50%            0.016130          -0.002604  ...              0.010254   \n",
              "75%            0.038770           0.024507  ...              0.044165   \n",
              "max            0.145364           0.128301  ...              0.194616   \n",
              "\n",
              "       195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n",
              "count           1213.000000           1213.000000           1213.000000   \n",
              "mean              -0.004938             -0.004378              0.001610   \n",
              "std                0.046536              0.042900              0.047424   \n",
              "min               -0.176523             -0.178688             -0.138048   \n",
              "25%               -0.033424             -0.033798             -0.030132   \n",
              "50%               -0.004683             -0.003724              0.000990   \n",
              "75%                0.024913              0.024007              0.032268   \n",
              "max                0.183152              0.180562              0.192015   \n",
              "\n",
              "       196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n",
              "count           1213.000000           1213.000000           1213.000000   \n",
              "mean               0.115171              0.049984              0.058144   \n",
              "std                0.057128              0.051664              0.057674   \n",
              "min               -0.070094             -0.153540             -0.131455   \n",
              "25%                0.080291              0.015827              0.022316   \n",
              "50%                0.113640              0.052705              0.059151   \n",
              "75%                0.150524              0.082526              0.095192   \n",
              "max                0.375635              0.228748              0.322084   \n",
              "\n",
              "       197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n",
              "count           1213.000000           1213.000000           1213.000000  \n",
              "mean               0.093527              0.089403              0.128946  \n",
              "std                0.054594              0.058036              0.058490  \n",
              "min               -0.085566             -0.204160             -0.083077  \n",
              "25%                0.059621              0.053224              0.090459  \n",
              "50%                0.093397              0.088612              0.127913  \n",
              "75%                0.127144              0.127613              0.166523  \n",
              "max                0.348153              0.267162              0.414304  \n",
              "\n",
              "[8 rows x 19900 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2888de96-8fb3-4837-9f16-6eafe5654d02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0throw_1thcolumn</th>\n",
              "      <th>0throw_2thcolumn</th>\n",
              "      <th>0throw_3thcolumn</th>\n",
              "      <th>0throw_4thcolumn</th>\n",
              "      <th>0throw_5thcolumn</th>\n",
              "      <th>0throw_6thcolumn</th>\n",
              "      <th>0throw_7thcolumn</th>\n",
              "      <th>0throw_8thcolumn</th>\n",
              "      <th>0throw_9thcolumn</th>\n",
              "      <th>0throw_10thcolumn</th>\n",
              "      <th>...</th>\n",
              "      <th>195throw_196thcolumn</th>\n",
              "      <th>195throw_197thcolumn</th>\n",
              "      <th>195throw_198thcolumn</th>\n",
              "      <th>195throw_199thcolumn</th>\n",
              "      <th>196throw_197thcolumn</th>\n",
              "      <th>196throw_198thcolumn</th>\n",
              "      <th>196throw_199thcolumn</th>\n",
              "      <th>197throw_198thcolumn</th>\n",
              "      <th>197throw_199thcolumn</th>\n",
              "      <th>198throw_199thcolumn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.060553</td>\n",
              "      <td>0.122315</td>\n",
              "      <td>0.060268</td>\n",
              "      <td>0.041287</td>\n",
              "      <td>0.069722</td>\n",
              "      <td>0.091007</td>\n",
              "      <td>0.066852</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.014128</td>\n",
              "      <td>-0.002914</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011075</td>\n",
              "      <td>-0.004938</td>\n",
              "      <td>-0.004378</td>\n",
              "      <td>0.001610</td>\n",
              "      <td>0.115171</td>\n",
              "      <td>0.049984</td>\n",
              "      <td>0.058144</td>\n",
              "      <td>0.093527</td>\n",
              "      <td>0.089403</td>\n",
              "      <td>0.128946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.064178</td>\n",
              "      <td>0.054026</td>\n",
              "      <td>0.057495</td>\n",
              "      <td>0.043491</td>\n",
              "      <td>0.044222</td>\n",
              "      <td>0.049189</td>\n",
              "      <td>0.046864</td>\n",
              "      <td>0.049046</td>\n",
              "      <td>0.038205</td>\n",
              "      <td>0.042462</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049632</td>\n",
              "      <td>0.046536</td>\n",
              "      <td>0.042900</td>\n",
              "      <td>0.047424</td>\n",
              "      <td>0.057128</td>\n",
              "      <td>0.051664</td>\n",
              "      <td>0.057674</td>\n",
              "      <td>0.054594</td>\n",
              "      <td>0.058036</td>\n",
              "      <td>0.058490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.183279</td>\n",
              "      <td>-0.059932</td>\n",
              "      <td>-0.145566</td>\n",
              "      <td>-0.127827</td>\n",
              "      <td>-0.072043</td>\n",
              "      <td>-0.079184</td>\n",
              "      <td>-0.105722</td>\n",
              "      <td>-0.164297</td>\n",
              "      <td>-0.137728</td>\n",
              "      <td>-0.148490</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.161666</td>\n",
              "      <td>-0.176523</td>\n",
              "      <td>-0.178688</td>\n",
              "      <td>-0.138048</td>\n",
              "      <td>-0.070094</td>\n",
              "      <td>-0.153540</td>\n",
              "      <td>-0.131455</td>\n",
              "      <td>-0.085566</td>\n",
              "      <td>-0.204160</td>\n",
              "      <td>-0.083077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.018482</td>\n",
              "      <td>0.086102</td>\n",
              "      <td>0.026548</td>\n",
              "      <td>0.014457</td>\n",
              "      <td>0.042462</td>\n",
              "      <td>0.057614</td>\n",
              "      <td>0.036934</td>\n",
              "      <td>-0.031358</td>\n",
              "      <td>-0.010635</td>\n",
              "      <td>-0.030538</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.021376</td>\n",
              "      <td>-0.033424</td>\n",
              "      <td>-0.033798</td>\n",
              "      <td>-0.030132</td>\n",
              "      <td>0.080291</td>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.022316</td>\n",
              "      <td>0.059621</td>\n",
              "      <td>0.053224</td>\n",
              "      <td>0.090459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.058276</td>\n",
              "      <td>0.123220</td>\n",
              "      <td>0.061339</td>\n",
              "      <td>0.043246</td>\n",
              "      <td>0.067066</td>\n",
              "      <td>0.086494</td>\n",
              "      <td>0.067247</td>\n",
              "      <td>0.002549</td>\n",
              "      <td>0.016130</td>\n",
              "      <td>-0.002604</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010254</td>\n",
              "      <td>-0.004683</td>\n",
              "      <td>-0.003724</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.113640</td>\n",
              "      <td>0.052705</td>\n",
              "      <td>0.059151</td>\n",
              "      <td>0.093397</td>\n",
              "      <td>0.088612</td>\n",
              "      <td>0.127913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.100103</td>\n",
              "      <td>0.154518</td>\n",
              "      <td>0.099056</td>\n",
              "      <td>0.068408</td>\n",
              "      <td>0.096504</td>\n",
              "      <td>0.119404</td>\n",
              "      <td>0.095117</td>\n",
              "      <td>0.031053</td>\n",
              "      <td>0.038770</td>\n",
              "      <td>0.024507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044165</td>\n",
              "      <td>0.024913</td>\n",
              "      <td>0.024007</td>\n",
              "      <td>0.032268</td>\n",
              "      <td>0.150524</td>\n",
              "      <td>0.082526</td>\n",
              "      <td>0.095192</td>\n",
              "      <td>0.127144</td>\n",
              "      <td>0.127613</td>\n",
              "      <td>0.166523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.321522</td>\n",
              "      <td>0.390895</td>\n",
              "      <td>0.278429</td>\n",
              "      <td>0.189825</td>\n",
              "      <td>0.317500</td>\n",
              "      <td>0.316811</td>\n",
              "      <td>0.270018</td>\n",
              "      <td>0.168196</td>\n",
              "      <td>0.145364</td>\n",
              "      <td>0.128301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.194616</td>\n",
              "      <td>0.183152</td>\n",
              "      <td>0.180562</td>\n",
              "      <td>0.192015</td>\n",
              "      <td>0.375635</td>\n",
              "      <td>0.228748</td>\n",
              "      <td>0.322084</td>\n",
              "      <td>0.348153</td>\n",
              "      <td>0.267162</td>\n",
              "      <td>0.414304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 19900 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2888de96-8fb3-4837-9f16-6eafe5654d02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2888de96-8fb3-4837-9f16-6eafe5654d02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2888de96-8fb3-4837-9f16-6eafe5654d02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a396234d-1982-4eeb-95ea-792a9edab90f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a396234d-1982-4eeb-95ea-792a9edab90f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a396234d-1982-4eeb-95ea-792a9edab90f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcm.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "F6paWgMU_Ti7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2a8c7d-cc3c-4e8d-cf7b-df4c37c76ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcm.head()"
      ],
      "metadata": {
        "id": "bfGS0noEBaha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "21f05e85-7dde-4992-e5fc-c8dda168a75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  participant_id  0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  \\\n",
              "0   70z8Q2xdTXM3          0.093473          0.146902          0.067893   \n",
              "1   WHWymJu6zNZi          0.029580          0.179323          0.112933   \n",
              "2   4PAQp1M6EyAo         -0.051580          0.139734          0.068295   \n",
              "3   obEacy4Of68I          0.016273          0.204702          0.115980   \n",
              "4   s7WzzDcmDOhF          0.065771          0.098714          0.097604   \n",
              "\n",
              "   0throw_4thcolumn  0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  \\\n",
              "0          0.015141          0.070221          0.063997          0.055382   \n",
              "1          0.038291          0.104899          0.064250          0.008488   \n",
              "2          0.046991          0.111085          0.026978          0.151377   \n",
              "3          0.043103          0.056431          0.057615          0.055773   \n",
              "4          0.112988          0.071139          0.085607          0.019392   \n",
              "\n",
              "   0throw_8thcolumn  0throw_9thcolumn  ...  195throw_196thcolumn  \\\n",
              "0         -0.035335          0.068583  ...              0.003404   \n",
              "1          0.077505         -0.004750  ...             -0.008409   \n",
              "2          0.021198          0.083721  ...              0.053245   \n",
              "3          0.075030          0.001033  ...             -0.023918   \n",
              "4         -0.036403         -0.020375  ...              0.066439   \n",
              "\n",
              "   195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n",
              "0             -0.010359             -0.050968             -0.014365   \n",
              "1             -0.008479              0.020891              0.017754   \n",
              "2             -0.028003              0.028773              0.024556   \n",
              "3             -0.005356              0.018607              0.016193   \n",
              "4             -0.076680             -0.047530             -0.031443   \n",
              "\n",
              "   196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n",
              "0              0.128066              0.112646             -0.058980   \n",
              "1              0.094040              0.035141              0.032537   \n",
              "2              0.166343              0.058925              0.035485   \n",
              "3              0.072955              0.130135              0.056120   \n",
              "4              0.221213              0.007343              0.005763   \n",
              "\n",
              "   197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n",
              "0              0.028228              0.133582              0.143372  \n",
              "1              0.075007              0.115350              0.138200  \n",
              "2              0.063661              0.042862              0.162162  \n",
              "3              0.084784              0.114148              0.190584  \n",
              "4              0.083820              0.079582              0.067269  \n",
              "\n",
              "[5 rows x 19901 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b228564-9cf4-4218-a404-1029f5cf9cfa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>0throw_1thcolumn</th>\n",
              "      <th>0throw_2thcolumn</th>\n",
              "      <th>0throw_3thcolumn</th>\n",
              "      <th>0throw_4thcolumn</th>\n",
              "      <th>0throw_5thcolumn</th>\n",
              "      <th>0throw_6thcolumn</th>\n",
              "      <th>0throw_7thcolumn</th>\n",
              "      <th>0throw_8thcolumn</th>\n",
              "      <th>0throw_9thcolumn</th>\n",
              "      <th>...</th>\n",
              "      <th>195throw_196thcolumn</th>\n",
              "      <th>195throw_197thcolumn</th>\n",
              "      <th>195throw_198thcolumn</th>\n",
              "      <th>195throw_199thcolumn</th>\n",
              "      <th>196throw_197thcolumn</th>\n",
              "      <th>196throw_198thcolumn</th>\n",
              "      <th>196throw_199thcolumn</th>\n",
              "      <th>197throw_198thcolumn</th>\n",
              "      <th>197throw_199thcolumn</th>\n",
              "      <th>198throw_199thcolumn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70z8Q2xdTXM3</td>\n",
              "      <td>0.093473</td>\n",
              "      <td>0.146902</td>\n",
              "      <td>0.067893</td>\n",
              "      <td>0.015141</td>\n",
              "      <td>0.070221</td>\n",
              "      <td>0.063997</td>\n",
              "      <td>0.055382</td>\n",
              "      <td>-0.035335</td>\n",
              "      <td>0.068583</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>-0.010359</td>\n",
              "      <td>-0.050968</td>\n",
              "      <td>-0.014365</td>\n",
              "      <td>0.128066</td>\n",
              "      <td>0.112646</td>\n",
              "      <td>-0.058980</td>\n",
              "      <td>0.028228</td>\n",
              "      <td>0.133582</td>\n",
              "      <td>0.143372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WHWymJu6zNZi</td>\n",
              "      <td>0.029580</td>\n",
              "      <td>0.179323</td>\n",
              "      <td>0.112933</td>\n",
              "      <td>0.038291</td>\n",
              "      <td>0.104899</td>\n",
              "      <td>0.064250</td>\n",
              "      <td>0.008488</td>\n",
              "      <td>0.077505</td>\n",
              "      <td>-0.004750</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008409</td>\n",
              "      <td>-0.008479</td>\n",
              "      <td>0.020891</td>\n",
              "      <td>0.017754</td>\n",
              "      <td>0.094040</td>\n",
              "      <td>0.035141</td>\n",
              "      <td>0.032537</td>\n",
              "      <td>0.075007</td>\n",
              "      <td>0.115350</td>\n",
              "      <td>0.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4PAQp1M6EyAo</td>\n",
              "      <td>-0.051580</td>\n",
              "      <td>0.139734</td>\n",
              "      <td>0.068295</td>\n",
              "      <td>0.046991</td>\n",
              "      <td>0.111085</td>\n",
              "      <td>0.026978</td>\n",
              "      <td>0.151377</td>\n",
              "      <td>0.021198</td>\n",
              "      <td>0.083721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.053245</td>\n",
              "      <td>-0.028003</td>\n",
              "      <td>0.028773</td>\n",
              "      <td>0.024556</td>\n",
              "      <td>0.166343</td>\n",
              "      <td>0.058925</td>\n",
              "      <td>0.035485</td>\n",
              "      <td>0.063661</td>\n",
              "      <td>0.042862</td>\n",
              "      <td>0.162162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>obEacy4Of68I</td>\n",
              "      <td>0.016273</td>\n",
              "      <td>0.204702</td>\n",
              "      <td>0.115980</td>\n",
              "      <td>0.043103</td>\n",
              "      <td>0.056431</td>\n",
              "      <td>0.057615</td>\n",
              "      <td>0.055773</td>\n",
              "      <td>0.075030</td>\n",
              "      <td>0.001033</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023918</td>\n",
              "      <td>-0.005356</td>\n",
              "      <td>0.018607</td>\n",
              "      <td>0.016193</td>\n",
              "      <td>0.072955</td>\n",
              "      <td>0.130135</td>\n",
              "      <td>0.056120</td>\n",
              "      <td>0.084784</td>\n",
              "      <td>0.114148</td>\n",
              "      <td>0.190584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s7WzzDcmDOhF</td>\n",
              "      <td>0.065771</td>\n",
              "      <td>0.098714</td>\n",
              "      <td>0.097604</td>\n",
              "      <td>0.112988</td>\n",
              "      <td>0.071139</td>\n",
              "      <td>0.085607</td>\n",
              "      <td>0.019392</td>\n",
              "      <td>-0.036403</td>\n",
              "      <td>-0.020375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066439</td>\n",
              "      <td>-0.076680</td>\n",
              "      <td>-0.047530</td>\n",
              "      <td>-0.031443</td>\n",
              "      <td>0.221213</td>\n",
              "      <td>0.007343</td>\n",
              "      <td>0.005763</td>\n",
              "      <td>0.083820</td>\n",
              "      <td>0.079582</td>\n",
              "      <td>0.067269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 19901 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b228564-9cf4-4218-a404-1029f5cf9cfa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b228564-9cf4-4218-a404-1029f5cf9cfa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b228564-9cf4-4218-a404-1029f5cf9cfa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e650a74-b687-4458-a3dd-01bec35b0f36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e650a74-b687-4458-a3dd-01bec35b0f36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e650a74-b687-4458-a3dd-01bec35b0f36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "fcm"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I was going to graph below, but each participants fcms need to be a numpy array for this to work so it doesn't run for now."
      ],
      "metadata": {
        "id": "os2RS7e1EVqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example data\n",
        "# Assume `matrices` is a list of connectivity matrices (2D arrays) for all individuals\n",
        "# Assume `labels` is a list of binary labels (0 or 1) corresponding to each individual\n",
        "\n",
        "# Separate matrices into two groups based on labels\n",
        "group_0 = [graph_fcm[i] for i in range(len(graph_fcm)) if graph_fcm.ADHD_Outcome[i] == 0]\n",
        "group_1 = [graph_fcm[i] for i in range(len(graph_fcm)) if graph_fcm.ADHD_Outcome[i] == 1]\n",
        "\n",
        "# Compute average connectivity matrices for each group\n",
        "avg_matrix_0 = np.mean(group_0, axis=0)\n",
        "avg_matrix_1 = np.mean(group_1, axis=0)\n",
        "\n",
        "# Visualize the average matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot group 0\n",
        "sns.heatmap(avg_matrix_0, ax=axes[0], cmap=\"coolwarm\", vmin=0, vmax=1, square=True, cbar=True)\n",
        "axes[0].set_title(\"Group 0 (Label = 0)\")\n",
        "\n",
        "# Plot group 1\n",
        "sns.heatmap(avg_matrix_1, ax=axes[1], cmap=\"coolwarm\", vmin=0, vmax=1, square=True, cbar=True)\n",
        "axes[1].set_title(\"Group 1 (Label = 1)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: Compute and visualize the difference between the two groups\n",
        "difference_matrix = avg_matrix_1 - avg_matrix_0\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(difference_matrix, cmap=\"coolwarm\", center=0, square=True, cbar=True)\n",
        "plt.title(\"Difference (Group 1 - Group 0)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Xn4WLYLCkq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_fcm.columns"
      ],
      "metadata": {
        "id": "RYBkvmQkDsjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10565a40-e976-42d4-b5ff-77ce9669297c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['participant_id', '0throw_1thcolumn', '0throw_2thcolumn',\n",
              "       '0throw_3thcolumn', '0throw_4thcolumn', '0throw_5thcolumn',\n",
              "       '0throw_6thcolumn', '0throw_7thcolumn', '0throw_8thcolumn',\n",
              "       '0throw_9thcolumn',\n",
              "       ...\n",
              "       '195throw_198thcolumn', '195throw_199thcolumn', '196throw_197thcolumn',\n",
              "       '196throw_198thcolumn', '196throw_199thcolumn', '197throw_198thcolumn',\n",
              "       '197throw_199thcolumn', '198throw_199thcolumn', 'ADHD_Outcome',\n",
              "       'Sex_F'],\n",
              "      dtype='object', length=19903)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph_fcm.isna().sum().sum()) #sum of missing values along all cols. shld be zero."
      ],
      "metadata": {
        "id": "fdeqQazdA9aX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892690b8-b373-40dc-dae1-35ae65397d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Data Exploration </h2>\n",
        "\n",
        "Doesn't seem to be missing any values. Checking the distribution of ADHD_Outcome and Sex_F."
      ],
      "metadata": {
        "id": "X6WHYlu8FIay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(x='ADHD_Outcome', data=graph_fcm)\n",
        "plt.title('Distribution of ADHD Outcome')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(x='Sex_F', data=graph_fcm)\n",
        "plt.title('Distribution of Sex (Female)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N4d7OWoDC6IZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "1f9282e2-4417-4195-9aba-13d5981f7986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok looks like there is still way more male ADHD data than female. We can consider training on only the female if the accuracy is bad there. Now graphing the average connectivity of the matrices"
      ],
      "metadata": {
        "id": "18D2MXk4GX8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Extract connectivity strength columns (excluding participant_id and ADHD_Outcome)\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
        "\n",
        "# Calculate the average connectivity strength for each connection\n",
        "average_connectivity = graph_fcm[connectivity_columns].mean()\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "average_connectivity.plot(kind='bar')\n",
        "plt.xlabel('Connection (Vertex Pair)')\n",
        "plt.ylabel('Average Connectivity Strength')\n",
        "plt.title('Average Connectivity Strengths Between Vertices')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pKZis_X3DGeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summary of below cells**\n",
        "\n",
        "Can't seem to better than 0.6851\n",
        "\n",
        "### Google Collab Code\n",
        "\n",
        "Aka runnable version of above code\n",
        "\n",
        "| Label | Accuracy | Nodes |\n",
        "|-------|----------|-------|\n",
        "| ADHD  | 0.6851   | fully-connected |\n",
        "|Sex_F  | 0.6570   | fully-connected |\n",
        "| ADHD  | 0.8450   | half connected  |\n",
        "| Sex_F | 0.8195   | half connected  |\n",
        "\n",
        "### Class Weights to Minority\n",
        "\n",
        "| Label | Accuracy |\n",
        "|-------|----------|\n",
        "| ADHD  | 0.5      |\n",
        "\n",
        "\n",
        "### SMOTE - Oversampling minority\n",
        "\n",
        "\n",
        "| Label | Accuracy |\n",
        "|-------|----------|\n",
        "| ADHD  | 0.5      |\n",
        "|Sex_F  | 0.5      |\n",
        "\n",
        "### Different GCN\n",
        "\n",
        "| Label | Accuracy | Learning Rate |\n",
        "|-------|----------|---------------|\n",
        "| ADHD  | 0.6851   | 0.01          |\n",
        "| ADHD  | 0.6851   | 0.05          |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DbAeEcVsrBRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN\n",
        "\n",
        "Both have such high losses they are randomly guessing so.\n",
        "\n",
        "Predicting ADHD"
      ],
      "metadata": {
        "id": "6EQ3O1p-aoSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")"
      ],
      "metadata": {
        "id": "zc4iiEOBbL_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "a6sML1CRdhNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08db485b-5ad7-4cf0-94c4-b2fd9640fd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6911\n",
            "Epoch 50, Loss: 0.6272\n",
            "Epoch 100, Loss: 0.6230\n",
            "Epoch 150, Loss: 0.6230\n",
            "Accuracy: 0.6851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Sex_F with same model as above"
      ],
      "metadata": {
        "id": "imsqRNwuayjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")"
      ],
      "metadata": {
        "id": "8kF_X0KMbSQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('ADHD_Outcome', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_f = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_f.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_f.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_f(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_f.eval()\n",
        "_, pred = model_f(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SAiqbrjanKC",
        "outputId": "71ba6f51-c9e9-40c0-b760-acfdcfc71f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6920\n",
            "Epoch 50, Loss: 0.6448\n",
            "Epoch 100, Loss: 0.6430\n",
            "Epoch 150, Loss: 0.6430\n",
            "Accuracy: 0.6570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Class Weights to Above Models\n",
        "\n",
        "To add more weight to minority classes (female and non-adhd) to see if it improves model accuracy because without it, the testing model just guessed not female and has adhd for every participant ;,("
      ],
      "metadata": {
        "id": "3UxFUxDxht3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADHD_Outcome\n",
        "\n",
        "Basically same outcome so i didn't try it on Sex_f"
      ],
      "metadata": {
        "id": "d7MpABIJh9vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "from sklearn.utils.class_weight import compute_class_weight #for weightsi\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "#Weights\n",
        "#compute weights\n",
        "labels_np = labels.astype(int)\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels_np), y=labels_np)\n",
        "#convert to pytorch tensor and move to device\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights) #add argument to this to account for weights\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d82Awp5iBAz",
        "outputId": "890a01c7-2ae3-4f67-a916-336d0155bf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6932\n",
            "Epoch 50, Loss: 0.6932\n",
            "Epoch 100, Loss: 0.6931\n",
            "Epoch 150, Loss: 0.6931\n",
            "Accuracy: 0.6851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using oversampling of minority class\n",
        "\n",
        "Using SMOTE (Synthetic Minority Over-sampling Technique)"
      ],
      "metadata": {
        "id": "sHz5jw_skpMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADHD outcome\n",
        "\n",
        "50% is worse bruh"
      ],
      "metadata": {
        "id": "FdeBHqBak48q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "########### BALANCING MINORITIES ###############\n",
        "# identifying minority class in tester (no ADHD is minority in training, might not be for tester but i doubt it, but we'll check anyways)\n",
        "minority_class = 0 if np.sum(labels == 1) > np.sum(labels == 0) else 1\n",
        "\n",
        "minority_indices = np.where(labels == minority_class)[0]\n",
        "majority_indices = np.where(labels != minority_class)[0]\n",
        "\n",
        "#ovesample minority bu duplicating them\n",
        "num_minority_needed = len(majority_indices) - len(minority_indices)\n",
        "oversampled_minority_indices = np.random.choice(minority_indices, num_minority_needed, replace=True)\n",
        "\n",
        "#combine all new duplicated min. with original where minority and majority class are balanced\n",
        "balanced_indices = np.concatenate([majority_indices, minority_indices, oversampled_minority_indices])\n",
        "\n",
        "# get new features and labels\n",
        "features_balanced = features[balanced_indices]\n",
        "labels_balanced = labels[balanced_indices]\n",
        "\n",
        "#################################################\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features_balanced.shape[0]  # CHANGED TO FATURED_BALANCED // Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device (change to featured_balanced)\n",
        "data = Data(\n",
        "    x=torch.tensor(features_balanced, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels_balanced, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "548i3k1bj6zO",
        "outputId": "51554232-86a1-4ede-a398-e5e8f3de5dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6932\n",
            "Epoch 50, Loss: 0.6931\n",
            "Epoch 100, Loss: 0.6931\n",
            "Epoch 150, Loss: 0.6931\n",
            "Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sex_f bc why not\n",
        "\n",
        "same result"
      ],
      "metadata": {
        "id": "5AwhGOMdqQWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('ADHD_Outcome', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "\n",
        "########### BALANCING MINORITIES ###############\n",
        "# identifying minority class in tester (no ADHD is minority in training, might not be for tester but i doubt it, but we'll check anyways)\n",
        "minority_class = 0 if np.sum(labels == 1) > np.sum(labels == 0) else 1\n",
        "\n",
        "minority_indices = np.where(labels == minority_class)[0]\n",
        "majority_indices = np.where(labels != minority_class)[0]\n",
        "\n",
        "#ovesample minority bu duplicating them\n",
        "num_minority_needed = len(majority_indices) - len(minority_indices)\n",
        "oversampled_minority_indices = np.random.choice(minority_indices, num_minority_needed, replace=True)\n",
        "\n",
        "#combine all new duplicated min. with original where minority and majority class are balanced\n",
        "balanced_indices = np.concatenate([majority_indices, minority_indices, oversampled_minority_indices])\n",
        "\n",
        "# get new features and labels\n",
        "features_balanced = features[balanced_indices]\n",
        "labels_balanced = labels[balanced_indices]\n",
        "\n",
        "#################################################\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features_balanced.shape[0]  # CHANGED TO FATURED_BALANCED // Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device (change to featured_balanced)\n",
        "data = Data(\n",
        "    x=torch.tensor(features_balanced, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels_balanced, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBpHJ6jQqPlX",
        "outputId": "3d934c36-7d8b-43a9-ad29-24c7d5a0050d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6935\n",
            "Epoch 50, Loss: 0.6932\n",
            "Epoch 100, Loss: 0.6931\n",
            "Epoch 150, Loss: 0.6931\n",
            "Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying more GCN Model\n",
        "\n",
        "More layers, BatchNorm, ReLU, and Dropout (prevent overfitting)"
      ],
      "metadata": {
        "id": "l7mP1r-rsuNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADHD_Outcome"
      ],
      "metadata": {
        "id": "s2KuHRKzs2sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels) #batch norm\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = torch.nn.Dropout(0.5) #dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.05\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4UmXwSNqwLi",
        "outputId": "b8d666d0-6781-4395-dc53-8417c8e93b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6931\n",
            "Epoch 50, Loss: 0.6230\n",
            "Epoch 100, Loss: 0.6230\n",
            "Epoch 150, Loss: 0.6230\n",
            "Accuracy: 0.6851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying Less Connected Graph\n",
        "\n",
        "half connected\n",
        "Overall: BETTER OUTCOME! .72 on submission\n",
        "\n",
        "1/3 connected\n",
        "Overall: Worse, 0.71 on submission\n",
        "\n",
        "ADHD Outcome\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "02FavhHhu1Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5))) #LITERALLY JUST DIVIDED IN HALF SO ITS NOT FULLY CONNECTED ITS HALF CONNECTED?\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thp2Uq2tu4bk",
        "outputId": "35b33c01-1026-41e8-e3e2-0cad6f841a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6834\n",
            "Epoch 50, Loss: 0.4669\n",
            "Epoch 100, Loss: 0.4087\n",
            "Epoch 150, Loss: 0.4146\n",
            "Accuracy: 0.8590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sex_F"
      ],
      "metadata": {
        "id": "4vWHP308zG2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('ADHD_Outcome', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5)))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_f = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_f.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_f.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_f(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_f.eval()\n",
        "_, pred = model_f(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShkMqNQrzGcT",
        "outputId": "33253ac8-574d-411d-926c-b86fdebac813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6828\n",
            "Epoch 50, Loss: 0.4605\n",
            "Epoch 100, Loss: 0.4175\n",
            "Epoch 150, Loss: 0.3724\n",
            "Accuracy: 0.8706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K nearest nodes and weights on important brain regions"
      ],
      "metadata": {
        "id": "EciJ2dNT9sn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(This doesn't work lol)\n",
        "ADHD_Outcome"
      ],
      "metadata": {
        "id": "Al_NlSVz9x8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix with actual adjacency correlations\n",
        "adjacency_matrix = np.abs(np.corrcoef(features, rowvar=False))\n",
        "adjacency_matrix[adjacency_matrix < 0.5] = 0  # Apply threshold\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "# K nearest neighbors\n",
        "\n",
        "k = 5\n",
        "top_k_mask = np.zeros_like(adjacency_matrix)  # Fixed initialization\n",
        "for i in range(adjacency_matrix.shape[0]):  # Iterate over rows (brain regions)\n",
        "    top_k_indices = np.argsort(adjacency_matrix[i])[-k:]  # Get top-K most correlated regions\n",
        "    top_k_mask[i, top_k_indices] = adjacency_matrix[i, top_k_indices]  # Keep only top-K\n",
        "\n",
        "adjacency_matrix = top_k_mask  # Update adjacency matrix\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "edge_index = np.array(np.where(adjacency_matrix > 0))  # Extract edges\n",
        "edge_weight = adjacency_matrix[edge_index[0], edge_index[1]]  # Extract weights\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(edge_index, dtype=torch.long).to(device),\n",
        "    edge_attr=torch.tensor(edge_weight, dtype=torch.float32).to(device),  # Edge weights\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "54uG2zZD9zZf",
        "outputId": "b2f6b921-edb5-4534-90b8-e5d9b3417efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-678ceb12af92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_adhd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-678ceb12af92>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'source_to_target'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle Submission\n",
        "Based on the Google Collab running\n",
        "\n",
        "Both are predicting only not female and ADHD, I think this may be due to the imbalance in the dataset"
      ],
      "metadata": {
        "id": "BmIZqxvTbhZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_fcm = pd.read_csv('TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')"
      ],
      "metadata": {
        "id": "Yzs4Cu5BZ5q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_fcm.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp64aa60aLYY",
        "outputId": "d06da474-3a0a-4890-c292-9870aff78b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['participant_id', '0throw_1thcolumn', '0throw_2thcolumn',\n",
              "       '0throw_3thcolumn', '0throw_4thcolumn', '0throw_5thcolumn',\n",
              "       '0throw_6thcolumn', '0throw_7thcolumn', '0throw_8thcolumn',\n",
              "       '0throw_9thcolumn',\n",
              "       ...\n",
              "       '195throw_196thcolumn', '195throw_197thcolumn', '195throw_198thcolumn',\n",
              "       '195throw_199thcolumn', '196throw_197thcolumn', '196throw_198thcolumn',\n",
              "       '196throw_199thcolumn', '197throw_198thcolumn', '197throw_199thcolumn',\n",
              "       '198throw_199thcolumn'],\n",
              "      dtype='object', length=19901)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_fcm.isna().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8_LiqfeaNQX",
        "outputId": "f9158e76-7335-4ce1-fa17-31e750b36651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting ADHD_Outcome\n"
      ],
      "metadata": {
        "id": "WLL0wSH5cJJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### GET TEST SET IN PROPER FORM LIKE WE DID WITH TRAINING #######\n",
        "# Prepare test data (ensure it follows the same preprocessing as training data)\n",
        "test_features = test_fcm[connectivity_columns].values\n",
        "num_test_nodes = test_features.shape[0]\n",
        "\n",
        "# Create an adjacency matrix for test data (modify as needed)\n",
        "test_adjacency_matrix = np.ones(((int)(num_test_nodes/2.5), (int)(num_test_nodes/2.5)))\n",
        "np.fill_diagonal(test_adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert test data to PyTorch Geometric format\n",
        "test_data = Data(\n",
        "    x=torch.tensor(test_features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(test_adjacency_matrix)), dtype=torch.long).to(device),\n",
        ")\n",
        "\n",
        "######## EVAL #########\n",
        "# put model in eval mode\n",
        "model_adhd.eval();\n",
        "\n",
        "# get predictions\n",
        "_, pred = model_adhd(test_data.x, test_data.edge_index).max(dim=1)\n",
        "\n",
        "# output\n",
        "output_adhd_df = pd.DataFrame({\n",
        "    'participant_id' : test_fcm['participant_id'].values,\n",
        "    'ADHD_Outcome' : pred.cpu().numpy() #make pred and convert to numpy\n",
        "})\n",
        "\n",
        "print(output_adhd_df)\n",
        "no_adhd_num = output_adhd_df[output_adhd_df['ADHD_Outcome'] == 0].shape[0]\n",
        "print(\"no adhd : \", no_adhd_num)\n",
        "print(\"adhd : \" , output_adhd_df.shape[0] - no_adhd_num)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNgj5ddPaQqR",
        "outputId": "859b5510-f9de-4688-b169-ad3e43c2ea18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    participant_id  ADHD_Outcome\n",
            "0     Cfwaf5FX7jWK             1\n",
            "1     vhGrzmvA3Hjq             1\n",
            "2     ULliyEXjy4OV             1\n",
            "3     LZfeAb1xMtql             1\n",
            "4     EnFOUv0YK1RG             1\n",
            "..             ...           ...\n",
            "299   UadZfjdEg7eG             1\n",
            "300   IUEHiLmQAqCi             1\n",
            "301   cRySmCadYFRO             1\n",
            "302   E3MvDUtJadc5             1\n",
            "303   dQJXfyRazknD             1\n",
            "\n",
            "[304 rows x 2 columns]\n",
            "no adhd :  5\n",
            "adhd :  299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting Sex_F"
      ],
      "metadata": {
        "id": "B3ZsoLRUfcz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### GET TEST SET IN PROPER FORM LIKE WE DID WITH TRAINING #######\n",
        "# Prepare test data (ensure it follows the same preprocessing as training data)\n",
        "test_features = test_fcm[connectivity_columns].values\n",
        "num_test_nodes = test_features.shape[0]\n",
        "\n",
        "# Create an adjacency matrix for test data (modify as needed)\n",
        "test_adjacency_matrix = np.ones(((int)(num_test_nodes/2.5), (int)(num_test_nodes/2.5)))\n",
        "np.fill_diagonal(test_adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert test data to PyTorch Geometric format\n",
        "test_data = Data(\n",
        "    x=torch.tensor(test_features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(test_adjacency_matrix)), dtype=torch.long).to(device),\n",
        ")\n",
        "\n",
        "######## EVAL #########\n",
        "# put model in eval mode\n",
        "model_f.eval();\n",
        "\n",
        "# get predictions\n",
        "_, pred = model_f(test_data.x, test_data.edge_index).max(dim=1)\n",
        "\n",
        "# output\n",
        "output_f_df = pd.DataFrame({\n",
        "    'participant_id' : test_fcm['participant_id'].values,\n",
        "    'Sex_F' : pred.cpu().numpy() #make pred and convert to numpy\n",
        "})\n",
        "\n",
        "print(output_f_df)\n",
        "no_f_num = output_f_df[output_f_df['Sex_F'] == 0].shape[0]\n",
        "print(\"not female: \", no_f_num)\n",
        "print(\"female : \" , output_f_df.shape[0] - no_f_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjPEXAGkc2Tm",
        "outputId": "4c1e6426-eeba-45a0-9fa8-433aa5ca1392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    participant_id  Sex_F\n",
            "0     Cfwaf5FX7jWK      1\n",
            "1     vhGrzmvA3Hjq      1\n",
            "2     ULliyEXjy4OV      1\n",
            "3     LZfeAb1xMtql      1\n",
            "4     EnFOUv0YK1RG      1\n",
            "..             ...    ...\n",
            "299   UadZfjdEg7eG      1\n",
            "300   IUEHiLmQAqCi      1\n",
            "301   cRySmCadYFRO      1\n",
            "302   E3MvDUtJadc5      1\n",
            "303   dQJXfyRazknD      1\n",
            "\n",
            "[304 rows x 2 columns]\n",
            "not female:  2\n",
            "female :  302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merging predictions\n",
        "final_pred = output_adhd_df.merge(output_f_df, on=\"participant_id\")\n",
        "final_pred.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XJJYPutC1RYq",
        "outputId": "86eca4e9-5d80-464d-ee25-b21dc1e26354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  participant_id  ADHD_Outcome  Sex_F\n",
              "0   Cfwaf5FX7jWK             1      1\n",
              "1   vhGrzmvA3Hjq             1      1\n",
              "2   ULliyEXjy4OV             1      1\n",
              "3   LZfeAb1xMtql             1      1\n",
              "4   EnFOUv0YK1RG             1      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3984bd08-77ce-466a-bd5e-4e55318ee5a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>ADHD_Outcome</th>\n",
              "      <th>Sex_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cfwaf5FX7jWK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhGrzmvA3Hjq</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ULliyEXjy4OV</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LZfeAb1xMtql</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EnFOUv0YK1RG</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3984bd08-77ce-466a-bd5e-4e55318ee5a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3984bd08-77ce-466a-bd5e-4e55318ee5a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3984bd08-77ce-466a-bd5e-4e55318ee5a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e32de29a-57a2-42a5-8251-47785f8d9d2c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e32de29a-57a2-42a5-8251-47785f8d9d2c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e32de29a-57a2-42a5-8251-47785f8d9d2c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_pred",
              "summary": "{\n  \"name\": \"final_pred\",\n  \"rows\": 304,\n  \"fields\": [\n    {\n      \"column\": \"participant_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          \"G4HH3C3252g1\",\n          \"DkwrzlcjCXzl\",\n          \"m4i3mVopmQND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADHD_Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "final_pred.to_csv('pred.csv', index=False)\n",
        "files.download('pred.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Sw2vRqNczsdr",
        "outputId": "3832b101-c88a-4b71-a136-74c6b387c7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40bc195e-0e41-4481-8800-8349e6e94d3c\", \"pred.csv\", 5202)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just making sure its in the correct format\n",
        "pred = pd.read_csv('pred.csv')\n",
        "pred.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Dos3NVnl0nbO",
        "outputId": "0880b12e-7be0-4d75-ae35-8e2662f18e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  participant_id  ADHD_Outcome  Sex_F\n",
              "0   Cfwaf5FX7jWK             1      1\n",
              "1   vhGrzmvA3Hjq             1      1\n",
              "2   ULliyEXjy4OV             1      1\n",
              "3   LZfeAb1xMtql             1      1\n",
              "4   EnFOUv0YK1RG             1      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01549b1f-a461-47e2-89e4-d74c0b1ebc58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>ADHD_Outcome</th>\n",
              "      <th>Sex_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cfwaf5FX7jWK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhGrzmvA3Hjq</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ULliyEXjy4OV</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LZfeAb1xMtql</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EnFOUv0YK1RG</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01549b1f-a461-47e2-89e4-d74c0b1ebc58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01549b1f-a461-47e2-89e4-d74c0b1ebc58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01549b1f-a461-47e2-89e4-d74c0b1ebc58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b1eb037-e161-4ce4-a490-e9e8889f1867\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b1eb037-e161-4ce4-a490-e9e8889f1867')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b1eb037-e161-4ce4-a490-e9e8889f1867 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pred",
              "summary": "{\n  \"name\": \"pred\",\n  \"rows\": 304,\n  \"fields\": [\n    {\n      \"column\": \"participant_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          \"G4HH3C3252g1\",\n          \"DkwrzlcjCXzl\",\n          \"m4i3mVopmQND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADHD_Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Dg-1wuF0zy4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}